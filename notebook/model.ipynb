{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a0a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b2c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\kanha\\Desktop\\Sap_assignment\\data\\ner_dataset.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3404809b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1          NaN             of   IN   O\n",
       "2          NaN  demonstrators  NNS   O\n",
       "3          NaN           have  VBP   O\n",
       "4          NaN        marched  VBN   O"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3c98d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentence #'] = df['Sentence #'].ffill()\n",
    "\n",
    "# Group by sentence\n",
    "sentences = []\n",
    "for _, group in df.groupby('Sentence #'):\n",
    "    sentence = list(zip(group['Word'], group['POS'], group['Tag']))\n",
    "    sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ba21c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of tokens (words)\n",
    "total_tokens = len(df)\n",
    "\n",
    "# Total number of sentences\n",
    "total_sentences = df['Sentence #'].nunique()\n",
    "\n",
    "# Number of unique tags (NER labels)\n",
    "unique_tags = df['Tag'].unique()\n",
    "num_unique_tags = len(unique_tags)\n",
    "\n",
    "# Number of unique words\n",
    "num_unique_words = df['Word'].nunique()\n",
    "\n",
    "# Number of unique POS tags\n",
    "num_unique_pos = df['POS'].nunique()\n",
    "\n",
    "# Distribution of entity tags\n",
    "tag_counts = df['Tag'].value_counts()\n",
    "\n",
    "# Top 10 most frequent words\n",
    "top_words = df['Word'].value_counts().head(10)\n",
    "\n",
    "# Average sentence length (in tokens)\n",
    "avg_sentence_len = df.groupby('Sentence #')['Word'].count().mean()\n",
    "\n",
    "# Max sentence length\n",
    "max_sentence_len = df.groupby('Sentence #')['Word'].count().max()\n",
    "\n",
    "# Min sentence length\n",
    "min_sentence_len = df.groupby('Sentence #')['Word'].count().min()\n",
    "\n",
    "# Count of entities (excluding \"O\")\n",
    "entity_only = df[df['Tag'] != 'O']['Tag'].value_counts()\n",
    "\n",
    "# Example tagged sentence\n",
    "sample_sentence = df[df['Sentence #'] == df['Sentence #'].unique()[0]][['Word', 'Tag']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96427fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Total tokens: 1048575\n",
      "2. Total sentences: 47959\n",
      "3. Unique NER tags: ['O' 'B-geo' 'B-gpe' 'B-per' 'I-geo' 'B-org' 'I-org' 'B-tim' 'B-art'\n",
      " 'I-art' 'I-per' 'I-gpe' 'I-tim' 'B-nat' 'B-eve' 'I-eve' 'I-nat']\n",
      "4. Number of unique tags: 17\n",
      "5. Number of unique words: 35177\n",
      "6. Number of unique POS tags: 42\n",
      "7. Tag distribution:\n",
      "Tag\n",
      "O        887908\n",
      "B-geo     37644\n",
      "B-tim     20333\n",
      "B-org     20143\n",
      "I-per     17251\n",
      "B-per     16990\n",
      "I-org     16784\n",
      "B-gpe     15870\n",
      "I-geo      7414\n",
      "I-tim      6528\n",
      "B-art       402\n",
      "B-eve       308\n",
      "I-art       297\n",
      "I-eve       253\n",
      "B-nat       201\n",
      "I-gpe       198\n",
      "I-nat        51\n",
      "Name: count, dtype: int64\n",
      "8. Top 10 most frequent words:\n",
      "Word\n",
      "the    52573\n",
      ".      47761\n",
      ",      32754\n",
      "of     26354\n",
      "in     26323\n",
      "to     23213\n",
      "a      20481\n",
      "and    19936\n",
      "The    11313\n",
      "'s     10923\n",
      "Name: count, dtype: int64\n",
      "9. Average sentence length: 21.86 tokens\n",
      "10. Max sentence length: 104\n",
      "11. Min sentence length: 1\n",
      "12. Named Entity Tag counts (excluding 'O'):\n",
      "Tag\n",
      "B-geo    37644\n",
      "B-tim    20333\n",
      "B-org    20143\n",
      "I-per    17251\n",
      "B-per    16990\n",
      "I-org    16784\n",
      "B-gpe    15870\n",
      "I-geo     7414\n",
      "I-tim     6528\n",
      "B-art      402\n",
      "B-eve      308\n",
      "I-art      297\n",
      "I-eve      253\n",
      "B-nat      201\n",
      "I-gpe      198\n",
      "I-nat       51\n",
      "Name: count, dtype: int64\n",
      "13. Sample tagged sentence:\n",
      "             Word    Tag\n",
      "0       Thousands      O\n",
      "1              of      O\n",
      "2   demonstrators      O\n",
      "3            have      O\n",
      "4         marched      O\n",
      "5         through      O\n",
      "6          London  B-geo\n",
      "7              to      O\n",
      "8         protest      O\n",
      "9             the      O\n",
      "10            war      O\n",
      "11             in      O\n",
      "12           Iraq  B-geo\n",
      "13            and      O\n",
      "14         demand      O\n",
      "15            the      O\n",
      "16     withdrawal      O\n",
      "17             of      O\n",
      "18        British  B-gpe\n",
      "19         troops      O\n",
      "20           from      O\n",
      "21           that      O\n",
      "22        country      O\n",
      "23              .      O\n"
     ]
    }
   ],
   "source": [
    "print(f\"1. Total tokens: {total_tokens}\")\n",
    "print(f\"2. Total sentences: {total_sentences}\")\n",
    "print(f\"3. Unique NER tags: {unique_tags}\")\n",
    "print(f\"4. Number of unique tags: {num_unique_tags}\")\n",
    "print(f\"5. Number of unique words: {num_unique_words}\")\n",
    "print(f\"6. Number of unique POS tags: {num_unique_pos}\")\n",
    "print(f\"7. Tag distribution:\\n{tag_counts}\")\n",
    "print(f\"8. Top 10 most frequent words:\\n{top_words}\")\n",
    "print(f\"9. Average sentence length: {avg_sentence_len:.2f} tokens\")\n",
    "print(f\"10. Max sentence length: {max_sentence_len}\")\n",
    "print(f\"11. Min sentence length: {min_sentence_len}\")\n",
    "print(f\"12. Named Entity Tag counts (excluding 'O'):\\n{entity_only}\")\n",
    "print(f\"13. Sample tagged sentence:\\n{sample_sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7719ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
